---
title: "Lecture notes"
---

# Overview

**2025-08-25**

## Quick why

- Frequentist uses only observed patterns to make decision. Least squares and even maximum likelihood estimator are all frequentist. Bayesian is completely different approach, based on priors (experience, expert opinion, or similar study). 
- When N is low, F estimates are not very reliable. e.g., coin toss 5 times gives 4 heads, but $P = 0.8$ is not very reliable, and it would be good to incorporate our prior information that the coin is fair ($P = 0.5$). Also, F doesn’t allow us to calculate bias in parameters, e.g., $p(P(H) > 0.5)$—it considers these parameters as fixed and not as random variables.
- Importantly, **prior information is incorporated in a prior distribution**, which is a critical component of Bayesian analysis.

## What

- Aim with the course is to show advantages of Bayesian in certain circumstances. In some cases, B results more interpretable than F. 
- British mathematician and minister Thomas Bayes. Ideas of Bayes’ Theorem posthumously published in 1763 by Pierce. But strong integration in practice only recently, due to technological revolution (strong compute).
- Bayesian *versus* frequentist dichotomy a thing of the past. BeiBei considers herself to be pragmatic, using F approaches for simple problems, large sample sizes, or when no priors, even though 90%+ of her research uses B.
- $\theta$ is prior, $D$ is data. Posterior distribution = $p( \theta | D )$, i.e., Bayesian estimate. $p(D)$ is marginal likelihood, very difficult to estimate, but MCMC methods do not require this estimation.
- Single-parameter models are easy to fit under B (e.g., binomial, poisson). Multiple-parameter models are difficult (e.g., normal distribution, simple regression).

## Interpretability of F & B

- Uncertainty/confidence:
    - Correct interpretation of F CI: if you take a large number of samples and construct CI for each, then **95% of those intervals will overlap the true value**. --> not very intuitive or interpretable, not very useful. 
    - In B, since parameters are treated as random variables, we CAN estimate an interval such that the **parameter is in that interval with exact probability**---which is the more intuitive definition of "uncertainty".
    - One way of calculating CI in F is Wald CI (normal approximation), but poor when $N$ is low. Other better alternatives sometimes approach B style. 
- p-value:
    - In F, interpreted as $p(\text{outcome at least as extreme as observed outcome} | H_0)$, not $p(H_0)$. 
    - But B allows us to estimate $p(H_0)$ and $p(H_1)$
- Data samples:
    - F assumes data are a repeatable random sample
    - B considers data as observed from the realised sample---data are fixed, do not care about data not observed.
- Inference:
    - In F, inference is based on likelihood, $L(D|\theta)$ (data|parameter)
    - In B, inference is based on posterior estimate of parameter, $P(\theta|D)$ (prior|data)

# Frequentist & Bayesian estimation

**2025-08-27**

## Prior and posterior

- In many cases parameter of interest ($\theta$) is related to proportion/prevalence/probability. 
    - In these cases, distribution of data ($D$) is binomial, i.e., probability of something. This is similar to F methods, e.g., using GLMs with binomial distribution to infer about probability/proportion of something. 
    - But distribution of parameter ($\theta$) is beta, i.e., proportion of something. This distribution is unique to B methods, and so is having to think about the appropriate parameter space distribution.
    - Beta distribution has two parameters $\alpha$ and $\beta$, and the sample size $N = \alpha + \beta$. Again, an intuitive way of describing the distribution of probability/proportion/odds? parameters. 
    - $B = [0, 1]$, i.e., mini normal distribution (not really truncated).
- Estimate of $\theta$:
    - F gives point estimate, although there is the possibility of calculating non-intuitive CIs
    - Estimate in B is a probability distribution (i.e., posterior distribution), and it is possible to also calculate summary stats of the distribution, like mean, median, etc.
    - The y-axis of such PDFs can be interpreted as the likelihoods of each probability value on the x-axis---each of which can be thought of as an F estimate.
- Likelihood is therefore important in both F and B! F uses maximum likelihood estimator (MLE).

```{r}
# explore probability mass function of binomial distribution

# probability of getting 0 successes out of 20 when p(success) is 0.5
dbinom(0, 20, 0.5) 
plot(0:20, dbinom(0:20, 20, 0.5)) 

# when success prob is lower:
plot(0:20, dbinom(0:20, 20, 0.05)) 

```

- Compromise between prior and data:
    - If $N(D)$ is large, posterior estimate tends closer to $D$, but if small tends closer to prior $\theta$.
    - On the other hand, if confidence in prior is high (i.e., low $sd(\theta)$), posterior estimate tends closer to prior $\theta$.
    - **Major critique** from F side about B methods: not objective enough, due to contingence on prior definitions (mean and sd). Prior distribution has to be justified! (Contingence on $N(D)$ is shared between F and B.)
    - Rule of thumb for beta distribution: $sd(\theta)$ = 0.05 is very confident, $sd(\theta)$ = 0.2 is very unconfident (means 95% between 0.1 and 0.9 for mean = 0.5).
    
## Defining priors

- Three ways of calculating priors:
    - Conjugate: when both prior and posterior follow the same data distribution family. Generally *easier computation and convenient*.
    - Historical: use historical info (e.g., fair coin p = 0.5)
    - Non-informative prior: no prior information, e.g., uniform distribution, or U-shaped (unfair coin). (Why is latter considered non-informative? Will see later in course.)
- Distribution families:
    - Beta is a mini normal distribution. We can also use truncated t distribution (t is similar to normal, just with fatter tails), or truncated chi-sq (like normal but only positive values) or truncated F.
    - But some of these are difficult to get summary values from if posterior also that distribution: they don’t give closed-form distributions (area under curve sums to 1). 
    - Beta priors on the other hand give closed-form posterior distributions and therefore allow easy summaries---for binomial sampling distribution of data.
    - What prior distribution gives closed-form posterior distribution depends on sampling model distribution (distribution of data). Under binomial sampling distribution, a beta prior leads to a beta posterior. But e.g. normal sampling beta prior does not give closed-form posterior.

## Posterior estimate

- Bayesian estimate gives an updated $\theta$ (posterior) distribution, which gives us even more info like:
	- Probabilites that the $\theta$ lies in a given interval
	- But also, conversely, defines interval (of given confidence, e.g, 95%) in which the parameter lies---the posterior credible interval, which has a probability interpretation.
- For estimating population mean:
	- F formula is pop-mean = sample-mean
	- B posterior mean (which is a summary value) is weighted average of sample mean and prior guess---incorporates sample size, prior confidence, and prior mean ($N(D)$, $sd(\theta)$, $\bar{\theta}$)---but formula depends on distribution of prior $\theta$.
	
	
```{r}
# explore beta distribution

# theta [0, 1] with corresponding probs for a beta(2, 20) distribution
plot(seq(0, 1, 0.01), 
     dbeta(seq(0, 1, 0.01), 2, 20)) 

# prob that theta < 0.2 for a beta(2, 20) distribution
pbeta(0.2, 2, 20) 
```

```{r}
# suppose, after incorporating prior and data, new beta(2, 40) distribution as 
# Bayesian estimate, but this estimate gives us more info than just distribution:

# updated theta [0, 1] with corresponding probs
plot(seq(0, 1, 0.01), 
     dbeta(seq(0, 1, 0.01), 2, 40)) 

# updated prob that theta < 0.2
pbeta(0.2, 2, 40) 

# prob that theta > 0.15 given our data and posterior dist
1 - pbeta(0.15, 2, 40) ; pbeta(0.15, 2, 40, lower.tail = FALSE)
```

```{r}
# these are probabilities that theta is in some interval
# conversely, posterior 95% credible interval:
qbeta(c(0.025, 0.975), 2, 40)
# which means P(0.006 < theta < 0.13 | data) = 0.95

# add CI to figure
plot(seq(0, 1, 0.01), 
     dbeta(seq(0, 1, 0.01), 2, 40)) 
rect(xleft = qbeta(c(0.025, 0.975), 2, 40)[1], 
     xright = qbeta(c(0.025, 0.975), 2, 40)[2], 
     ybottom = -1, ytop = 20,
     col = rgb(0,0.5,0.75, alpha = 0.25), border = NA)
```

# Probability concepts and Bayes Rule for events

- Unconditional probability: wrt sample space. Conditional probability: wrt **sample space updated based on posterior distribution** (new info).
- In the case of a fair die, for the first roll, $P(A) = \frac{1}{6}$, but based on what first roll outcome was, $P(A)$ changes according to the posterior distribution. 
- $A$ and $B$ are independent if $P(A|B) = P(A)$ or equivalently $P(A \cap B ) = P(A)P(B)$
- Law of total probability: $P(B) = P(B|A)P(A) + P(B|A^C)P(A^C)$ (extended to any number of $A$ partitions making up $S$)
- Bayes rule for two events: $P(A|B) = \frac{P(B|A)P(A)}{P(B)} = \frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|A^C)P(A^C)}$
    - For multiple events: $P(A_j|B) = \frac{P(B|A_j)P(A_j)}{P(B)} = \frac{P(B|A_j)P(A_j)}{\sum_{i=1}^{n} P(B|A_i)P(A_i)}$
- Joint distribution/two-way distribution: combine distribution of sample spaces of two variables together. Marginal distribution is usually the unconditional probability. 
- Bayesian updation of sample space based on posterior distribution does not change relative probabilities of each outcome but adjusts absolute values so that they add to 1 within this new sample space. The new value is old value divided by marginal probability of updated event.

# Bayes Rule (for events) examples, and probability distributions

- One example of widely accepted and non-controversial use of Bayes Rule is diagnostic tests like HIV tests. Here, sample space partition has four events: true positive, true negative, false positive, false negative. 
- Every random variable has an associated probability distribution. For discrete random variables, this is called probability mass function (pmf), while for continuous random variables it is called probability density function (pdf).
- Every random variable also has a cumulative distribution function (cdf; $F(y)$).
- **Unlike pmf, cdf is not restricted to sample space**. e.g., in Bernoulli trials, cdf is still defined for $y \lt 0$. $F(y) = P(Y \leq y)$.
- cdf of any discrete random variable is a step function. For Bernoulli, in the step function the size of jump at $y = 0$ equals the failure probability and size of jump at $y = 1$ is the success probability.

```{r}
curve(pbinom(x, 1, 0.3), -2, 2)
curve(pbinom(x, 1, 0.5), -2, 2)
```

- Binomial distribution is for series of Bernoulli trials with same success probability. e.g., number of heads in $n$ number of rolls. Bernoulli is a special case of binomial, where $n = 1$

```{r}
curve(pbinom(x, 8, 0.5), -1, 10)
```

- Every random variable also has an **expected value** or mean, where the mean is a weighted average based on the pmf. 
- We can estimate/approximate this mean by sampling a large number of numbers from the pmf and taking their mean.

```{r}
# Bernoulli
rand_nos <- rbinom(10000, 1, 0.1) # success p = 0.1
mean(rand_nos)

mean(rbinom(10, 1, 0.1)); mean(rbinom(100, 1, 0.1)); mean(rbinom(1000, 1, 0.1)); mean(rbinom(10000, 1, 0.1)); mean(rbinom(100000, 1, 0.1))
```

- Poisson sample space is 0 to infinity.
- Continuous random variables have sample space that's uncountable. Beta distribution sample space is the unit interval $[0,1]$.
- For continuous variable, probability of any single value is zero, so instead of pmf we use pdf. Where we sum individual probabilites in pmf, we integrate across in pdf.
- The difference is that for discrete, y axis is limited to 0 and 1, but for continuous this is not the case. Hence, pdf y-axis does not have probability interpretation like pmf, but relative likelihoods still remain.
- The cdf of continuous variable is: $F(a) = P(Y \le a) = \int_{-\infty}^{a} f(y)dy$
- Uniform distribution is not valid for range including infinity, because then the area under the curve doesn't sum to 1. However, in Bayesian stats, we use such distributions when selecting *improper priors*. 
- Normal distribution is symmetric, so cdf at mean value is 0.5.

```{r}
dnorm(0, 0, 1)
pnorm(0, 0, 1)
```

- Gamma is a continuous version of Poisson, so $(0,\infty)$
    - Exponential and chi-square are special cases of gamma.
    
Beta
    
- Uniform distribution is a special case of beta: $U(0, 1) = B(1, 1)$.
- Beta distribution with $\alpha = \beta$ yields symmetric distribution around 0.5.
- When $\alpha \lt 1$ and $\beta \lt 1$ the distribution is U-shaped. 
- Variance increases as $\alpha$ and $\beta$ decrease. 

## Questions

WHY doesn't y axis for continuous have probability interpretation?

- Infinity
- Probability associated with intervals, not single points (area under pdf curve between two points gives probability)
- PDF value denotes density: likelihood of variable being near a certain point (higher/lower)

Is it correct to say beta is continuous extension of Bernoulli?

No because they are fundamentally different concepts. But in Bayesian context, Beta is the probability distribution of Bernoulli probability. 

# Joint & conditional distributions, and likelihood function

**2025-09-10**

- Marginal distributions usually denoted using subscript: $f_x(x)$
- Conditional distribution for discrete RV consists of multiple individual conditional probabilities
- Conditional distribution of y given x: $f(y|x) = P(Y = y | x = x) = \frac{f(x,y)}{f_x(x)}$
- In most cases, we only use, and need, the unnormalised probability distributions (esp. for posterior) because getting normalised (which involves multiplication by a constant) is computationally demanding (to estimate the constant). But in any case, the unnormalised tells us relative proportions.
- Knowing marginal distributions cannot help construct joint distributions, because different joints can have the same marginals
- In multivariate case, just like in univariate, the pmf will become pdf, but here we need double integrals instead of single integrals. (Two dimensions, so one integral for each of x and y.)

Bayes rule for variables...

- Likelihood closely related to pdfs, but definition highlight key difference between F and B paradigms
- In F, parameters assumed fixed, and data are repeatable random sample (x and y random, theta or other params fixed). In B, parameters assumed random, data fixed (observed from realised sample). Likelihood Function is that function of theta given data which equals the pmf/pdf of data given theta.
- Likelihood Function used after data observed
- It is important in both F and B. Maximum Likelihood Estimator of parameter $\mu$ gives sample mean.

# Bayes Rule for variables

**2025-09-15**

- Relates to conditional & marginal distributions instead of events
- $f(x|y) = \frac{f(x,y)}{f(y)} = \frac{f(y|x)f(x)}{f(y)}$
- Key application of this rule is when $y$ is our data and $x$ is a model parameter/structure
- Sampling model (i.e., likelihood) specifies distribution based on data, but we want to convert that to posterior distribution of the parameter based on our data
- $posterior = (likelihood)(prior)/(marginal likelihood)$
- $p(\theta | D) = \frac{L(\theta | D) p(\theta)}{p(D)}$, where $D$ is the observed data, $\theta$ represents parameters 
- In Bayesian framework, hyper-parameters are parameters only in prior distribution and not in the sampling model (i.e., parameters given for prior $\theta$ distribution). Parameters appear in the likelihood (sampling model). Hyper-parameters can also be unknowns, and their prior distributions are called hyper-prior distributions.
- Priors may not be flat, but might still have small effect of posterior and are still considered non-informative priors.
- Calculation of marginal likelihood is most complicated step of Bayesian analysis, and is rarely actually done. But is a function of data only, not of parameter.
    - In practice, omission of this step just means we skip the normalising step that converts unnormalised distributions to exact posterior distributions (which are proportional to the unnormalised).
    - Therefore, $p(\theta | D) \propto L(\theta | D) p(\theta)$ (called "kernel")

An example to show calculations:

```{r}
n <- 12
y <- 3 
# observed data: 3 H out of 12 tosses
theta <- c(0.25, 0.5, 0.75) # limiting possible values for simplicity
prior <- c(0.25, 0.5, 0.25)

likelihood <- dbinom(y, n, theta) # pdf/pmf
unnorm_post <- prior*likelihood
marg_likelihood <- sum(unnorm_post) # normalising constant
(posterior <- unnorm_post/marg_likelihood)
```

```{r}
library(tidyverse)

df <- tibble(x = theta, y = prior, lab = "prior") %>% 
  bind_rows(tibble(x = theta, y = likelihood, lab = "likelihood")) %>% 
  bind_rows(tibble(x = theta, y = posterior, lab = "posterior")) %>% 
  mutate(lab = factor(lab, levels = c("prior", "likelihood", "posterior")))

ggplot(df) +
  geom_col(aes(x = x, y = y)) +
  scale_x_continuous(breaks = seq(0, 1, 0.25), limits = c(0, 1)) +
  scale_y_continuous(breaks = seq(0, 1, 0.2), limits = c(0, 1)) +
  facet_wrap(~ lab, ncol = 1, strip.position = "left") +
  labs(x = "theta", y = "") +
  theme_classic()
```

- $\theta$ we estimate has meaning only in specific context of sampling model we choose, so sometimes it's useful to explicitly state the model in mind
- Model comparison: can consider two different models as two different parameters you estimate (following Bayes rule). Then the ratio of the two posterior distributions is the posterior odds, which is a product of Bayes factor and prior odds.
    - Sometimes, posterior probabilities of both may be very similar, so instead of model selection you can do model averaging. Bayesian Model Averaging.

# Beta-binomial model

**2025-09-17**

- Three goals for inference from data:
    - Estimation of parameter values
    - Prediction of future data values (prior and posterior *predictive* distributions)
    - Model comparison
- Advantages of Bayesian Inference:
    - Incorporate external info
    - Account for sources of uncertainty
    - *Learning* paradigm: Sequential Analysis (apply Bayes's Rule repeatedly)
- Difficulties/Criticisms:
    - Specification of prior is critical but difficult
    - High-dimensional integrals
        - But no longer a concern since MCMC (allow fitting complex models without large sample approximations)
    - Seems subjective (contingent on priors)
        - Use concrete prior info if available, else noninformative/vague priors
        - When sample size large, effect of prior is much lower (unless prior is very peaked)
        - "Reality": Scientists often disagree, different knowledge bases. Bayesian methods allow us to actually formally incorporate this info in decision-making process. (e.g., model selection/averaging)
  
Beta-binomial model: A better non-informative prior for beta distribution (than uniform) is an inverse-U, because in this case the impact of the prior on posterior is even lower.

**2025-09-22**

- With MCMC don't need to do any integration
- If prior is beta, posterior is also beta
- Can get summary statistics either using equation by inputting parameters of posterior, or by MCMC which involves repeated sampling from the distribution (no need to know parameters).

```{r} 
23/(23+7); 23*7/((23+7)^2 * (23+7+1)) # easily know the equation
mcmc <- rbeta(10000, 23, 7); mean(mcmc); var(mcmc)
# but low MCMC sample size is bad
mcmc <- rbeta(5, 23, 7); mean(mcmc); var(mcmc)
```

Getting credible intervals:

```{r}
qbeta(c(0.025, 0.975), 23, 7) # 95% CI
pbeta(0.5, 23, 7, lower.tail = FALSE) # less than 50%
```

One way to incorporate uncertainty between your different sources of data when updating priors is to lower parameters of prior, e.g., instead of $B(5,5)$ can use $B(1,1)$ or $B(2,2)$.

**Sensitivity analysis for prior parameters**: posterior summaries for different $\alpha$ and $\beta$.

```{r}
18/21 # sample mean
# uniform prior (1,1) less influential on posterior
curve(dbeta(x, 19, 4), 0, 1) 
# more confident prior (100,100) more influential
curve(dbeta(x, 118, 103), 0, 1) 

```

- Data order invariance: updating of priors should give same final posterior regardless of order of intermediate posteriors and data, and even if you combine all the intermediate updations into one large updation.
- Credible interval (which is quantile-based) has an issue for asymmetric posteriors that some higher likelihood values are excluded from the interval and lower likelihood values are included. So, there is an alternative considering 95% highest posterior density (HPD) region instead.

**2025-09-24**

- HPD is that part of parameter space containing 95% values such that none of the values outside the interval have higher probability density than those inside (for unimodal, lower and upper quantiles have same).
- The width of the HPD region is another way of gauging uncertainty of beliefs
- If unimodal, HPD region is an interval, but else it's just a region

```{r}
library(binom)

binom.bayes(11, 14, type = "highest", prior.shape1 = 1, prior.shape2 = 1)
binom.bayes(11, 14, type = "highest", prior.shape1 = 100, prior.shape2 = 100)
# quantile-based
binom.bayes(11, 14, type = "central", prior.shape1 = 1, prior.shape2 = 1)

# save and plot density
line1 <- binom.bayes(11, 14, 
                     type = "central", prior.shape1 = 1, prior.shape2 = 1)
binom.bayes.densityplot(line1)
```

- Can build informative priors using quantile info. If we know equally likely that p is less than and greater than 0.3, and that 90% likely that p is greater than 0.5:

```{r}
library(LearnBayes)
quantile1 <- list(p = 0.5, x = 0.3)
quantile2 <- list(p = 0.9, x = 0.5)
beta.select(quantile1, quantile2)
qbeta(c(0.5, 0.9), 3.26, 7.19)
```

- Can use discrete priors if we don't want high precision

```{r}
p <- seq(0.05, 0.95, by = 0.1)
prior <- c(1, 5.2, 8, 7.2, 4.6, 2.1, 0.7, 0.1, 0, 0) # beliefs
prior <- prior/sum(prior) # normalise to sum to 1
plot(p, prior, type = "h", ylab = "prior probability")

# data: s=11, f=16
data <- c(11, 16)
post <- LearnBayes::pdisc(p, prior, data)
round(cbind(p, prior, post), 2)

```

After functionising, we can make quick comparisons of how sample size and prior parameters affect posterior updation.

```{r}
fn_post <- function(true_theta, n, prior_alpha, prior_beta) {
  
  set.seed(1)
  y <- rbinom(1, n, true_theta) # simulated observed successes
  post_alpha <- prior_alpha + y
  post_beta <- prior_beta + n - y
  
  curve(dbeta(x, prior_alpha, prior_beta),
        ylim = c(0, 11), lty = 3, lwd = 4, 
        xlab = expression(theta),
        ylab = "density",
        main = paste("prior sample size = ", 
                     prior_alpha + prior_beta,
                     "; n = ",
                     n))
  curve(dbeta(x, y + 1, n - y + 1),
        add = TRUE, lty = 2, lwd = 4)
  curve(dbeta(x, post_alpha, post_beta),
        add = TRUE, lty = 1, lwd = 4)
  legend(0, 10, c("Prior", "Likelihood", "Posterior"),
         lty = 3:1, lwd = 3)
  
}

par(mfrow = c(2, 2))
fn_post(true_theta = 0.8, n = 1, prior_alpha = 1.5, prior_beta = 6)
fn_post(true_theta = 0.8, n = 7, prior_alpha = 1.5, prior_beta = 6)
fn_post(true_theta = 0.8, n = 50, prior_alpha = 1.5, prior_beta = 6)
fn_post(true_theta = 0.8, n = 100, prior_alpha = 1.5, prior_beta = 6)

fn_post(true_theta = 0.8, n = 1, prior_alpha = 150, prior_beta = 600)
fn_post(true_theta = 0.8, n = 7, prior_alpha = 150, prior_beta = 600)
fn_post(true_theta = 0.8, n = 50, prior_alpha = 150, prior_beta = 600)
fn_post(true_theta = 0.8, n = 100, prior_alpha = 150, prior_beta = 600)
```


# Other conjugate models

**2025-09-29--10-01**

## Normal distribution 

Single parameter (known variance, estimate mean), one data point:

- Conjuage prior is normal distribution with hyperparameters known
- Precision is reciprocal of variance.
- In normal posterior distribution, mean and variance are more easily represented in terms of precision (because variance in denominator)
- $\mu_1 = \frac{\tau_0\mu_0 + \tau y}{\tau_0 + \tau}$ and $\tau_1 = \tau_0 + \tau$
- Posterior mean is still weighted average of prior mean and sample mean

```{r}
mu0 <- 0
sigma0sq <- 10^2
sigmasq <- 5^2
y <- -5.2

(sigma1sq <- 1/(1/sigma0sq + 1/sigmasq))
(mu1 <- (mu0/sigma0sq + y/sigmasq)*sigma1sq)

curve(dnorm(x, mu0, sqrt(sigma0sq)), # R function defines in mean and sd, not mean and var
      from = -25, to = 25,
      ylim = c(0, 0.09), lty = 3, lwd = 4, 
      xlab = expression(mu),
      ylab = "density")
curve(dnorm(x, y, sqrt(sigmasq)),
      add = TRUE, lty = 2, lwd = 4)
curve(dnorm(x, mu1, sqrt(sigma1sq)),
      add = TRUE, lty = 1, lwd = 4)
legend(8, 0.09, c("Prior", "Likelihood", "Posterior"),
       lty = 3:1, lwd = 3)
```

Single parameter (known variance, estimate mean), multiple data points:

- Easy way to estimate is slightly change parameters for posterior distribution as in case of one data point. Now becomes $N(\bar{\mu}, \frac{\sigma^2}{n})$
- $\mu_n = \frac{\tau_0\mu_0 + \tau \bar{y}}{\tau_0 + \tau}$ and $\tau_n = \tau_0 + \tau$ where $\tau = \frac{n}{\sigma^2}$ and rest remains the same.

Worked example:

```{r}
mu0 <- 180
sigma0sq <- 40^2
sigmasq <- 20^2
y <- c(145, 147, 155, 180, 110, 160, 120, 100, 130, 170)

# use the distribution of ybar
ybar <- mean(y)
n <- length(y)
sigmasq <- sigmasq/n

(sigmansq <- 1/(1/sigma0sq + 1/sigmasq))
(mun <- (mu0/sigma0sq + ybar/sigmasq)*sigmansq)

curve(dnorm(x, mu0, sqrt(sigma0sq)), # R function defines in mean and sd, not mean and var
      from = 100, to = 250,
      ylim = c(0, 0.07), lty = 3, lwd = 4, 
      xlab = expression(mu),
      ylab = "density")
curve(dnorm(x, ybar, sqrt(sigmasq)),
      add = TRUE, lty = 2, lwd = 4)
curve(dnorm(x, mun, sqrt(sigmansq)),
      add = TRUE, lty = 1, lwd = 4)
legend(200, 0.07, c("Prior", "Likelihood", "Posterior"),
       lty = 3:1, lwd = 3)
```

If prior mean is far from true mean, huge effect on posterior.

Single parameter (known mean, estimate variance), multiple data points:

- Now one part of likelihood function which we were ignoring as constant is no longer constant.
- Variance cannot take negative values, so prior cannot be normal or beta. 
- Gamma is a good candidate but is not a conjugate prior.
- Inverse gamma is a good conjugate prior.
- If we use a non-informative prior like uniform distribution in this case, the prior is an improper prior because the curve does not integrate to 1 (but to $\infty$), and it's not a probability distribution.
- This is not a problem if improper prior combined with likelihood gives proper posterior. But if posterior is also improper, it is not a probability distribution and therefore cannot make inference (cannot take mean or variance), so need to choose different prior.
- Proper priors always give proper posteriors. But there are certain well known improper priors which also always give proper posteriors.
- Special case of IG is when both $\alpha$ and $\beta$ are zero, which gives something that's not really an IG. But this is the standard non-informative prior. **Jeffreys default prior for variance of normal distribution**, and it is an improper prior.

Example:

```{r}
data <- read.table("../inv_gamma_data.txt", header = TRUE)
heights <- data[, 1]
n <- length(heights)
mu <- 67
alpha <- 5; beta <- 20
alpha_n <- alpha + n/2
beta_n <- beta + sum((heights - mu)^2)/2

# MCMC
library(MCMCpack)
posterior <- rinvgamma(10000, alpha_n, beta_n)
(post_mean <- mean(posterior))
(post_var <- var(posterior))

# exact
(beta_n/(alpha_n - 1)); (beta_n^2/((alpha_n - 1)^2 * (alpha_n-2)))
```

## Exponential distribution

- Special case of gamma when shape parameter $\alpha = 1$
- Conjugate prior is also gamma $Ga(\alpha, \beta)$
- Then posterior is $Ga(\alpha + n, \beta + \sum{x_i})$
- Default prior, Jeffreys prior ($p(\theta) \propto 1/\theta$), is improper when $\alpha = \beta = 0$ but posterior is still proper.
- Uniform prior is also possible in this case, because posterior will still be proper.

## Poisson distribution

- Conjugate prior is gamma 
- Getting exact calculation of posterior estimates might be difficult, so MCMC approximation is better.

```{r}
post1 <- rgamma(10000, 219, 112)
post2 <- rgamma(10000, 68, 45)
mean(post1 > post2)
```

- Posterior predictive distribution is a negative-binomial distribution $negbin(\alpha + t, \beta + n)$

```{r}
a <- 2
b <- 1
n1 <- 111
sy1 <- 217
n2 <- 44
sy2 <- 66

y <- 0:10 
dnbinom(y, size = (a + sy1), mu = (a + sy1) / (b + n1)) 
dnbinom(y, size = (a + sy2), mu = (a + sy2) / (b + n2)) 

# to predict prob that randomly selected new woman from one will have more kids than other
z1 <- rnbinom(10000, size = (a + sy1), mu = (a + sy1) / (b + n1))
z2 <- rnbinom(10000, size = (a + sy2), mu = (a + sy2) / (b + n2))
mean(z1 > z2)
# same number of kids
mean(z1 == z2)
```



# Conjugate priors and prior distributions

**2025-10-06--08**

## Priors

- Subjective vs objective (non-informative)
- Subjective
    - Conjugate
    - Non-conjugate: posterior is not closed-form, but with MCMC not a problem, just need more compute
- Objective
    - Reference
        - Non-informative
        - Likelihood dominates posterior
        - May not be probability distribution (not bounded; improper). Not major concern if posterior is proper. (Most cases this is true, but in complex models posterior can also be improper and one cannot make inference.)
        - Beta(0,0) is improper, and can give improper posterior if data yield 0 successes or failures (e.g., Beta(0,2)). Hence Beta(0.5,0.5) is more commonly used as a proper prior.
        - Constant/flat rule prior is not transformation invariant, distribution changes.
    - Jeffreys
        - Jeffreys priors remedy this, by ensuring same posterior inference for any transformation of parameter (even if posterior distribution itself is different).
        - Based on Fisher information.
        - Non-informative
        - Transformation invariant
        - Posterior may not be proper
        - Does not work well for multi-parameter models
    - Diffuse
        - Remedy improper posteriors in Jeffreys
        - Proper prior with little info about parameter (spread of prior measures uncertainty)
        - Diffuse: large SD, so weakly informative
    - Sometimes cannot use non-informative priors, like in model comparison or selection.
    - Bayes Factor quite sensitive to choices of hyperparameters of vague proper prios
- Can do sensitivity checks for choice of prior, especially in subjective priors. e.g., use Gamma and inverse Gamma separately to combine with likelihood (data) and get posterior; if posterior similar then can use either, if not, perhaps better to go with non-informative.

## Monte Carlo simulation

- Monte Carlo approximation generates independent values from posterior distribution, but MCMC generates dependent values (form a Markov Chain, one value depends only on previous).
- Generating values randomly using distribution functions in R (as done so far) is Monte Carlo approximation, not MCMC.
- For multivariate cases, we need joint distribution. Depending on whether the component distributions are known or not, we may need to use MCMC and generate non-independent values.

## Conjugate priors

- Easy to derive posterior, but expert opinion may not conform to conjugate prior and conjugates may not always exist.

```{r}
tibble::tribble(
  ~ "Sampling distribution", ~ "Conjugate prior",
  "Binomial(n, theta)", "Beta",
  "Poisson(theta)", "Gamma",
  "Exp(theta)", "Gamma",
  "N(theta, var), var known", "Normal",
  "N(mean, theta), mean known", "Inverse-gamma",
  "Gamma(alpha, theta), alpha known", "Gamma",
  "Pareto(x, theta), x known", "Gamma",
  "Weibull(theta, k), k known", "Inverse-gamma",
  "Inverse-gamma(alpha, theta), alpha known", "Gamma"
)
```

# Multi-parameter models: Normal model

**2025-10-13--15**

## Non-informative prior

- Easiest way is to assume independent priors for each parameters, so joint distribution will be product of each. (Prior beliefs about each parameter need to be independent.) But this may not be conjugate.
- Conditional posterior distribution of two-parameter normal distribution sample is Normal(mean, var/n), where var can be estimated as IG($\frac{n - 1}{2}, s^2 \frac{n - 1}{2}$). Marginal posterior distribution of mean is a non-standardised t-distribution.
- This can then be generated using MC.
- Good to avoid loops, can separately generate MC for each parameter.

## Example

Simon Newcomb set up an experiment in 1882 to measure the speed of light. He measured the amount of time required for light to travel a distance of 7442 m. Assume $y_i \sim N(\mu, \sigma^2)$ *iid*, $i = 1, ..., 66$. $\bar{y} = 26.2, s = 10.8$. Use both join analysis and marginal analysis to get the posterior distribution of $\mu$ assuming the non-informative prior.

```{r}
n <- 66
y_bar <- 26.2
var <- 10.8^2

# marginal approach

sample_t <- rt(10000, n-1)
sample_mu <- sample_t * sqrt(var/n) + y_bar

mean(sample_mu); quantile(sample_mu, c(0.025, 0.975))

# joint approach
library(MCMCpack)

sample_sigma2 <- rinvgamma(100000, (n - 1)/2, var * (n - 1)/2)
sample_mu <- rnorm(10000, y_bar, sqrt(sample_sigma2/n))
mean(sample_mu); quantile(sample_mu, c(0.025, 0.975))

# joint approach gives joint samples from joint distribution, but single column represents marginal
cbind(sample_mu, sample_sigma2)
```

## Conjugate prior

Normal-Inverse-Gamma prior:

$$ (\mu, \sigma^2) \sim NIG(\mu_0, \tau_0, \frac{\nu_0}{2}, \frac{SS_0^2}{2}) $$

where $\mu_0$ and $\tau_0$ are mean and sample of a set of prior observations, and $\nu_0$ and $SS_0^2$ are df and sum of squares (variance x df) of prior observations.

This conjugate prior not commonly used. $\mu$ and $\sigma^2$ are not independent in prior distributions.

$SS_n^2$ is posterior variation: prior variation + observed variation + variation between prior mean and sample mean.

Marginal posterior distribution of $\mu$:

$$ (\mu | x) \sim t_{\nu_n}(\mu_n, \frac{\sigma_n^2}{\tau_n}) , \sigma_n^2 = \frac{SS_n^2}{\nu_n}) $$

## Semi-conjugate prior

Independent priors for the parameters:

$$ \mu \sim N(\mu_0, \tau_0^2), \sigma^2 \sim IG(\frac{\nu_0}{2}, \frac{\nu_0}{2} \sigma_0^2) $$

In posterior, the two parameters are not independent, so not a conjugate prior. And is not closed-form. Posterior:

$$ \mu | \sigma^2, x \sim N(\mu_n, \tau_n^2) $$

Gibbs sampler uses these conditional distributions.

## Example: SPF

*(Very vague.)*

SPF 5 means an individual that can tolerate X minutes of sunlight without any sunscreen can tolerate 5X minutes with sunscreen. Data on 13 individuals (tolerance, in min, with and without sunscreen).

Model: Y = log(TRT) - log(CONTROL) ~ $N(\mu, \sigma^2)$. Then E(log(TRT/CONTROL)) = $\mu$ = log(SPF). Interested in exp($\mu$) = SPF. Summary stats: $\bar{y} = 1.998, s^2 = 0.525, n = 13$.

(Using log because regular ratio takes only positive values, and likely has positive skew. Log ratios can be assumed to follow normal.)

Prior information:  
    1. Prior median SPF is 16
    1. P(SPF > 64) = 0.01
    1. Information in prior is worth 25 observations

```{r}
require(MCMCpack)

# joint
n_post <- 10000
sample_sig2 <- rinvgamma(n_post, 37/2, 197.1/2)
sample_mu <- rnorm(n_post, 2.508, sqrt(sample_sig2/38))
post_samples <- cbind(sample_mu, sample_sig2)

# marginal mu
post_mu <- rt(n_post, 37) * sqrt(197.1/(37*38)) + 2.508

mean(post_mu); mean(post_samples[,1])

# SPF
post_SPF <- exp(post_mu)
hist(post_SPF)

# posterior predictive distribution
nu_n <- 37
tau_n <- 38
mu_n <- 2.508
SSn2 <- 197.1

sample_z <- rep(0, n_post)
for (i in 1:n_post) {
  sample_z[i] <- rnorm(1, post_samples[i, 1], sqrt(post_samples[i, 2]))
}
exp(sample_z)
quantile(exp(sample_z))
```



# Multi-parameter models: Multinomial model

**2025-10-20**

- Generalisation of binomial
- Basic example: roll of die (cf coin toss binomial)
- Discrete, so pmf not pdf
- Conjugate prior is Dirichlet distribution (non-negative values, sum to 1), $\theta \sim D(\alpha)$
- Posterior: $\theta | x \sim D(\alpha + x)$

```{r}
require(MCMCpack)

rdirichlet(1, c(1, 5, 4, 2))
sum(rdirichlet(1, c(1, 5, 4, 2)))

vec <- rdirichlet(100, c(5, 1, 7, 8))
apply(vec, 1, sum)
```

- Hyperparameters:
    - Sum of all $\alpha$ is number of prior trials (measure of prior confidence)
    - $\alpha_j$ is number of times the *j*th category occurs in prior trials
- Symmetric: all outcomes equally likely

# Markov Chain Monte Carlo

**2025-10-22**

- Need alternative methods to compute posterior distributions and summaries for non-conjugate priors.
- F use logistic regression more often, B use probit regression more often. Conjugate prior does not exist in either case.
- Markov Chain is a sequence of random variables, such that distribution of value at one point depends only on most recent point. *The future depends on the present and not the past.*
- Simulate from a Markov Chain whose stationary distribution is the desired posterior distribution (e.g., via Gibbs sampler and/or Metropolis-Hastings algorithms), then calculate MC estimates.
- Monte Carlo: most common statistical technique to perform integral approximation.
- In simple models, like those with conjugate prior, easy to derive posterior in closed form, and here MC sampling is not necessary but convenient.
- When posterior density does not have recognisable form, might be possible to factor the distribution and simulate in parts (as done for the normal model).
- For more complicated problems, may not possible to directly generate samples from target distribution (e.g., non-conjugate settings and situations where we cannot sample from joint posterior).

## Metropolis algorithm

- For single parameter models, Metropolis or Metropolis-Hastings. For multi-parameter, Gibbs Sampler with perhaps Metropolis within.
- Metropolis only requires prior and likelihood, which is the kernel of the posterior distribution. Produces an approximation of posterior distribution, in the form of a large number of $\theta$ values sampled from the posterior.
- Burn-in period: ignore first few iterations before distribution matches target distribution

```{r}
# suppose on island 4
rbinom(1, 1, 0.5)
# propose move to island 5

alpha <- 2
beta <- 2
y <- 1
sigma2 <- 1

post <- function(mu) {
  dnorm(mu, y, sqrt(sigma2)) * dgamma(mu, alpha, beta)
}
x <- seq(0.01, 10, 0.1)
y <- post(x)
plot(x, y) # cannot summarise, unnormalised

mu_current <- 0.2
mu_proposed <- 0.4
acc_prob <- min(1, post(mu_proposed)/post(mu_current))

r <- runif(1)
r < acc_prob
```
